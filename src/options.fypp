#:include "common.fypp"

module options_m

   use iso_fortran_env, only: int32, int64

   implicit none

   ! Specifics for handling options for the algorithms.
   ! For instance, it can hold first-touch, whether warm-up
   ! number of iterations, etc.
   private
   type, public :: options_t

      !< Number of iterations that are timed
      integer :: it = 10
      !< Number of iterations that are *not* timed
      integer :: warmup_it = 1
      !< Whether the arrays are using a parallel first-touch, otherwise serial
      logical :: first_touch = .true.
      !< Offset in allocation, just to ensure non-contiguity of array-allocations
      integer(${OMB_INT_KIND}$) :: offset = 0
      !< Number of threads maximal available. Mainly used for special benchmarks
      integer :: num_threads = 1

      !< Whether we should print-out debug info
      logical :: debug = .false.

      !< Whether we should print-out test info
      logical :: test = .false.

      !< Whether we should do a dry-run
      logical :: dryrun = .false.

      !< The kernel specification for the test runned.
      class(kernel_t), pointer :: kernel => null()

   end type

   !< Inheritable class to signal which kernel we will be using
   type, abstract, public :: kernel_t
   contains

      procedure, pass :: name => kernel_name

   end type

   !< Use no OpenMP clauses.
   type, public, extends(kernel_t) :: kernel_serial_t
   end type

   !< Use the parallel construct, then manual static splitting.
   type, public, extends(kernel_t) :: kernel_manual_t
   end type

   !< Use the parallel construct in manual simd construct.
   type, public, extends(kernel_manual_t) :: kernel_manual_simd_t
   end type

   !< Use the parallel construct in manual simd + nontemporal construct.
   type, public, extends(kernel_manual_simd_t) :: kernel_manual_simd_nontemporal_t
   end type

   !< Use the parallel do construct.
   type, public, extends(kernel_t) :: kernel_do_t
   end type

   !< Use the parallel do simd construct.
   type, public, extends(kernel_do_t) :: kernel_do_simd_t
   end type

   !< Use the parallel do simd nontemporal construct.
   type, public, extends(kernel_do_simd_t) :: kernel_do_simd_nontemporal_t
   end type

   !< Use the parallel workshare construct.
   type, public, extends(kernel_t) :: kernel_workshare_t
   end type

   !< Use the parallel taskloop construct.
   !<
   !< The taskloop construct adds an implicit taskgroup around.
   !< We default to use this because it is required for reduction
   !< operations.
   type, public, extends(kernel_t) :: kernel_taskloop_t
      integer(${OMB_INT_KIND}$) :: num_tasks = -1
   end type

   !< Use the parallel taskloop simd construct.
   !<
   !< The taskloop simd construct adds an implicit taskgroup around.
   !< We default to use this because it is required for reduction
   !< operations.
   type, public, extends(kernel_taskloop_t) :: kernel_taskloop_simd_t
   end type

   !< Use the parallel loop construct.
   type, public, extends(kernel_t) :: kernel_loop_t
   end type

   !< Global class for teams
   type, public, extends(kernel_t) :: kernel_teams_t
   end type

   !< Use the teams construct and the initial team thread for parallelism.
   !<
   !< This is somewhat equivalent to the distribute. However,
   !< it uses a manual segmentation of the loops.
   !< So the thread_limit is hardcoded to 1, and the num_teams is specified
   !< to be `num_threads`.
   !< Kind of abusing the teams constructs.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_t) :: kernel_teams_manual_t
   end type

   !< Use the teams distribute construct.
   !<
   !< This uses the distribute to utilize only the master threads
   !< of each team to perform the computation.
   !< So the thread_limit is hardcoded to 1, and the num_teams is specified
   !< to be `num_threads`.
   !< Kind of abusing the teams + distribute constructs.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_t) :: kernel_teams_distribute_t
   end type

   !< Use the teams distribute parallel do construct.
   !<
   !< This uses the distribute to utilize only the master threads
   !< of each team to perform the computation.
   !< So the thread_limit is hardcoded to 1, and the num_teams is specified
   !< to be `num_threads`.
   !< Kind of abusing the teams + distribute + parallel do constructs.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_distribute_t) :: kernel_teams_distribute_do_t
   end type

   !< Use the teams parallel construct.
   !<
   !< This uses the teams (force-fully sets num_team=1) and then uses
   !< the threads to a worksharing clause using `parallel` and a manual splitting.
   !< Kind of abusing the teams construct.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_t) :: kernel_teams_parallel_manual_t
   end type

   !< Use the teams parallel do construct.
   !<
   !< This uses the teams (force-fully sets num_team=1) and then uses
   !< the threads to a worksharing clause using `parallel do`.
   !< Kind of abusing the teams construct.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_t) :: kernel_teams_parallel_do_t
   end type

   !< Use the teams parallel loop construct.
   !<
   !< This uses the teams (force-fully sets num_team=1) and then uses
   !< the threads to a worksharing clause using `parallel loop`.
   !< Kind of abusing the teams construct.
   !<
   !< All teams constructs lack a synchronization technique
   !< because the barrier requires all threads in a team to participate.
   type, public, extends(kernel_teams_t) :: kernel_teams_parallel_loop_t
   end type

   public :: kernel_alloc

contains

   subroutine kernel_name(this, name)
      class(kernel_t), intent(in) :: this
      character(len=*), intent(out) :: name

      name = " "

      select type (this)
      type is (kernel_serial_t)
         name = "serial"
      type is (kernel_manual_t)
         name = "manual"
      type is (kernel_manual_simd_t)
         name = "manual:simd"
      type is (kernel_manual_simd_nontemporal_t)
         name = "manual:simd+nontemporal"
      type is (kernel_do_t)
         name = "do"
      type is (kernel_do_simd_t)
         name = "do:simd"
      type is (kernel_do_simd_nontemporal_t)
         name = "do:simd+nontemporal"
      type is (kernel_workshare_t)
         name = "workshare"
      type is (kernel_taskloop_t)
         name = "taskloop"
      type is (kernel_taskloop_simd_t)
         name = "taskloop:simd"
      type is (kernel_loop_t)
         name = "loop"
      type is (kernel_teams_manual_t)
         name = "teams:manual"
      type is (kernel_teams_distribute_t)
         name = "teams:distribute"
      type is (kernel_teams_distribute_do_t)
         name = "teams:distribute:do"
      type is (kernel_teams_parallel_manual_t)
         name = "teams:parallel:manual"
      type is (kernel_teams_parallel_do_t)
         name = "teams:parallel:do"
      type is (kernel_teams_parallel_loop_t)
         name = "teams:parallel:loop"
      class default
         name = "<unset>"
      end select

   end subroutine

   subroutine kernel_alloc(this, name)
      class(kernel_t), intent(inout), pointer :: this
      character(len=*), intent(in) :: name

      if (associated(this)) deallocate (this)
      nullify (this)

      select case (trim(name))
      case ("serial")
         allocate (kernel_serial_t::this)
      case ("manual")
         allocate (kernel_manual_t::this)
      case ("manual:simd")
         allocate (kernel_manual_simd_t::this)
         #:if defined("OMB_OMP_SIMD_NONTEMPORAL")
            case ("manual:simd+nontemporal")
            allocate (kernel_manual_simd_nontemporal_t::this)
         #:endif
      case ("do")
         allocate (kernel_do_t::this)
      case ("do:simd")
         allocate (kernel_do_simd_t::this)
         #:if defined("OMB_OMP_SIMD_NONTEMPORAL")
            case ("do:simd+nontemporal")
            allocate (kernel_do_simd_nontemporal_t::this)
         #:endif
      case ("workshare")
         allocate (kernel_workshare_t::this)
         #:if defined("OMB_OMP_TASKLOOP")
            case ("taskloop")
            allocate (kernel_taskloop_t::this)
            case ("taskloop:simd")
            allocate (kernel_taskloop_simd_t::this)
         #:endif
      case ("loop")
         allocate (kernel_loop_t::this)
         #:if defined("OMB_OMP_TEAMS")
            case ("teams:manual")
            allocate (kernel_teams_manual_t::this)
            #:if defined("OMB_OMP_TEAMS_DISTRIBUTE")
               case ("teams:distribute")
               allocate (kernel_teams_distribute_t::this)
               case ("teams:distribute:do")
               allocate (kernel_teams_distribute_do_t::this)
            #:endif
            #:if defined("OMB_OMP_TEAMS_PARALLEL")
               case ("teams:parallel:manual")
               allocate (kernel_teams_parallel_manual_t::this)
               case ("teams:parallel:do")
               allocate (kernel_teams_parallel_do_t::this)
               case ("teams:parallel:loop")
               allocate (kernel_teams_parallel_loop_t::this)
            #:endif
         #:endif
      end select

   end subroutine

end module
